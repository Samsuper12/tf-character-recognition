{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Char74K database\n",
    "\n",
    "http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "import urllib.request\n",
    "import tarfile\n",
    "import scipy.io\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using splits given by the authors has no sense here so I'll just split all of these once myself\n",
    "\n",
    "# def parse_lists_mat(filepath):\n",
    "#     matfile = scipy.io.loadmat(filepath)\n",
    "#     names = matfile['list'][0].dtype.names\n",
    "#     arrays = matfile['list'][0][0]\n",
    "#     lists_dict = {name: array for name, array in zip(names, arrays)}\n",
    "#     return lists_dict\n",
    "\n",
    "# for lists_file in [\n",
    "#     'tmp/Lists/English/Fnt/lists.20.mat',\n",
    "#     'tmp/Lists/English/Fnt/lists_var_size.mat',\n",
    "#     'tmp/Lists/English/Hnd/lists_var_size.mat',\n",
    "#     'tmp/Lists/English/Img/lists.mat',\n",
    "#     'tmp/Lists/English/Img/Backup/list_difficult.mat',\n",
    "# ]:\n",
    "#     print('\\n' + lists_file)\n",
    "#     lists_dict = parse_lists_mat(lists_file)\n",
    "#     for name, array in lists_dict.items():\n",
    "#         print('   %20s: %s' % (name, np.shape(array)))\n",
    "#     for name in ['TRNind', 'TSTind', 'VALind', 'TXNind']:\n",
    "#         print('   %10s -> %d' % (name, np.shape(lists_dict[name])[0] * np.shape(lists_dict[name])[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.getcwd()\n",
    "download_dir = os.path.join(base_dir, 'tmp')\n",
    "urls = [\n",
    "        'http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/EnglishImg.tgz',\n",
    "        'http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/EnglishHnd.tgz',\n",
    "        'http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/EnglishFnt.tgz',\n",
    "        'http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/Lists.tgz'\n",
    "    ]\n",
    "\n",
    "char47k_class_numbers = np.arange(1, 62+1)\n",
    "classes = '0123456789' + string.ascii_uppercase + string.ascii_lowercase\n",
    "assert len(classes) == len(char47k_class_numbers)\n",
    "# for spliting samples into training/test sets \"deterministically randomly\" - random-like but each time the same \n",
    "fixed_pseudorandom_seed = 135797531\n",
    "train_samples_percentage = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maybe_download():\n",
    "    if not os.path.exists(download_dir):\n",
    "        os.mkdir(download_dir)\n",
    "    print('Trying to download files...')\n",
    "    for url in urls:\n",
    "        name = url.split('/')[-1]\n",
    "        filepath = os.path.join(download_dir, name)\n",
    "        print('  ... %s ...' % name, end='')\n",
    "        if os.path.exists(filepath):\n",
    "            print(' exists')\n",
    "        else:\n",
    "            print(' downloading ...', end='')\n",
    "            urllib.request.urlretrieve(url, filepath)\n",
    "            print(' done')\n",
    "            \n",
    "def assert_tarfile(tar):\n",
    "    # whatever, just check if the archive is safe\n",
    "    assert all(not (name.startswith('/') or name.startswith('..')) for name in tar.getnames()), 'Dangerous tarfile?!'\n",
    "    \n",
    "\n",
    "def extract_samples(tar, tar_fromdir, destdir, print_base_str):\n",
    "    # tar_fromdir must be a path to the directory that consists only of direcotries SampleXXX with images\n",
    "    # filter only files from tar_fromdir, remove all temporary *~ files, remove non-files\n",
    "    tar_members = filter(lambda member: member.path.startswith(tar_fromdir), tar.getmembers())\n",
    "    tar_members = filter(lambda member: not member.path.endswith('~'), tar_members)\n",
    "    tar_members = filter(lambda member: member.isfile(), tar_members)\n",
    "    tar_members = list(tar_members)\n",
    "    # split files into classes and alter paths to remove preceiding directories \n",
    "    #  and verbosely name classes' directories\n",
    "    class_members = {class_name: [] for class_name in classes}\n",
    "    pattern = re.compile(r'Sample([0-9]{3})')\n",
    "    for member in tar_members:\n",
    "        member.path = member.path[len(tar_fromdir):]\n",
    "        match = pattern.search(member.path)\n",
    "        if match:\n",
    "            class_n = int(match.groups()[0])\n",
    "            new_class = classes[class_n - 1]\n",
    "            member.path = member.path[:match.start()] + new_class + member.path[match.end():]\n",
    "            class_members[new_class].append(member)\n",
    "    # class_members has structure {class: [all, image, files(TarInfo), from, that, class, ...]}\n",
    "    # split pseudo-randomly to train/test sets\n",
    "    # using fixed seed, so it should give the same results each time\n",
    "    np.random.seed(fixed_pseudorandom_seed)\n",
    "    train_members, test_members = [], []\n",
    "    for classname in class_members.keys():\n",
    "        np.random.shuffle(class_members[classname])\n",
    "        n_training = int(train_samples_percentage/100 * len(class_members[classname]))\n",
    "        train_members.extend(class_members[classname][:n_training])\n",
    "        test_members.extend(class_members[classname][n_training:])    \n",
    "    # extract files, doing it sequentially is MUCH faster (at least on HDD)\n",
    "    n_all = len(train_members) + len(test_members)\n",
    "    n_cur = 0\n",
    "    template = '\\r%s %{}d/%{}d'.format(len(str(n_all)), len(str(n_all)))\n",
    "    print_info = lambda n: print(template % (print_base_str, n, n_all), end='')\n",
    "    print_info(n_cur)\n",
    "    for member in tar.getmembers():\n",
    "        if member in train_members:\n",
    "            tar.extract(member, path=os.path.join(destdir, 'train'))\n",
    "        elif member in test_members:\n",
    "            tar.extract(member, path=os.path.join(destdir, 'test'))\n",
    "        else:\n",
    "            continue\n",
    "        n_cur += 1\n",
    "        print_info(n_cur)\n",
    "    last_string = template % (print_base_str, n_cur, n_all)\n",
    "    return last_string\n",
    "\n",
    "def unarchive():\n",
    "    # archive_mappings = {archive_name: [(in_archive_from_dir, to_dir), ...])\n",
    "    archive_mappings = {\n",
    "        'EnglishFnt.tgz': [('English/Fnt/',             'font/'    ), ],\n",
    "        'EnglishHnd.tgz': [('English/Hnd/Img/',         'hand/'    ), ],\n",
    "        'EnglishImg.tgz': [('English/Img/GoodImg/Bmp/', 'img_good/'), \n",
    "                           ('English/Img/BadImag/Bmp/', 'img_bad/' ), ],\n",
    "    }    \n",
    "    print('Extracting archives...')\n",
    "    for archive_name, mappings in archive_mappings.items():\n",
    "        base = '  ... %s' % archive_name\n",
    "        print('%s ... opening' % base, end='')\n",
    "        tar = tarfile.open(os.path.join(download_dir, archive_name))\n",
    "        assert_tarfile(tar)\n",
    "        base = '%s ... extracting ... ' % base \n",
    "        print('\\r' + base, end='')\n",
    "        for from_dir, to_dir in mappings:\n",
    "            if os.path.exists(to_dir):\n",
    "                base += 'exists ... '\n",
    "                print('\\r' + base, end='')\n",
    "                continue\n",
    "            last_string = extract_samples(tar, from_dir, os.path.join(base_dir, to_dir), print_base_str=base)\n",
    "            base = last_string + ' ... '\n",
    "            print('\\r' + base, end='')\n",
    "        print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to download files...\n",
      "  ... EnglishImg.tgz ... exists\n",
      "  ... EnglishHnd.tgz ... exists\n",
      "  ... EnglishFnt.tgz ... exists\n",
      "  ... Lists.tgz ... exists\n",
      "Extracting archives...\n",
      " ... EnglishFnt.tgz ... extracting ... exists ... done\n",
      " ... EnglishHnd.tgz ... extracting ... exists ... done\n",
      " ... EnglishImg.tgz ... extracting ...  7705/7705 ...  4798/4798 ... done\n"
     ]
    }
   ],
   "source": [
    "maybe_download()\n",
    "unarchive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (venv: default)",
   "language": "python",
   "name": "python3-default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
